{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Setup Gdrive file download extention \n","!conda install -y gdown"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import random\n","import concurrent.futures\n","from PIL import Image, ImageFilter, ImageEnhance\n","import numpy as np\n","\n","def apply_noise(image):\n","    noise_factor = round(random.uniform(4.5, 5.5), 1)\n","    print(\"noise\", noise_factor)\n","    img_array = np.array(image)\n","    noise = np.random.normal(loc=0, scale=5.0, size=img_array.shape)\n","    noisy_image = Image.fromarray(np.clip(img_array + noise, 0, 255).astype(np.uint8))\n","    return noisy_image\n","\n","def apply_gaussian_blur(image):\n","    blur_radius = round(random.uniform(4.5, 5.5), 1)\n","    print(\"blur\", blur_radius)\n","    return image.filter(ImageFilter.GaussianBlur(5.0))\n","\n","def apply_brightness(image):\n","    factor = round(random.uniform(1.2, 1.5), 1)\n","    print(\"factor br\", factor)\n","    enhancer = ImageEnhance.Brightness(image)\n","    bright_image = enhancer.enhance(1.4)\n","    return bright_image\n","\n","def apply_darkness(image):\n","    factor = round(random.uniform(0.5, 0.7), 1)\n","    print(\"dark\", factor)\n","    enhancer = ImageEnhance.Brightness(image)\n","    dark_image = enhancer.enhance(0.6)\n","    return dark_image\n","\n","def augment_and_save_image(input_folder, output_folder, filename):\n","    image_path = os.path.join(input_folder, filename)\n","    original_image = Image.open(image_path)\n","\n","    # Apply augmentation\n","    noisy_image = apply_noise(original_image)\n","    blurred_image = apply_gaussian_blur(original_image)\n","    bright_image = apply_brightness(original_image)\n","    dark_image = apply_darkness(original_image)\n","\n","    # Resize images to 320x320\n","    noisy_image = noisy_image.resize((1024, 1024))\n","    blurred_image = blurred_image.resize((1024, 1024))\n","    bright_image = bright_image.resize((1024, 1024))\n","    dark_image = dark_image.resize((1024, 1024))\n","\n","    # Save augmented images\n","    base_name, ext = os.path.splitext(filename)\n","    original_image.save(os.path.join(output_folder, f'{base_name}_org{ext}'))\n","\n","    noisy_image.save(os.path.join(output_folder, f'{base_name}_noisy{ext}'))\n","    blurred_image.save(os.path.join(output_folder, f'{base_name}_blurred{ext}'))\n","    bright_image.save(os.path.join(output_folder, f'{base_name}_bright{ext}'))\n","    dark_image.save(os.path.join(output_folder, f'{base_name}_dark{ext}'))\n","    print(\"done\")\n","\n","def augment_images(input_folder, output_folder):\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    with concurrent.futures.ThreadPoolExecutor() as executor:\n","        image_files = [filename for filename in os.listdir(input_folder) if filename.endswith(('.jpg', '.jpeg', '.png'))]\n","        futures = [executor.submit(augment_and_save_image, input_folder, output_folder, filename) for filename in image_files]\n","\n","        for future in concurrent.futures.as_completed(futures):\n","            try:\n","                future.result()\n","            except Exception as e:\n","                print(f\"An error occurred: {e}\")\n","\n","# Example usage\n","input_folder = '/content/train/Train/glaucoma'\n","output_folder = '/content/drive/MyDrive/augmented_image-10-march/glaucoma'\n","augment_images(input_folder, output_folder)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","\n","# Get the path to the folder containing the files.\n","folder_path = '/content/train/Train/normal'\n","\n","# Get a list of all files in the folder.\n","files = os.listdir(folder_path)\n","\n","# Delete the first 2000 files.\n","for file in files[:2000]:\n","    file_path = os.path.join(folder_path, file)\n","    os.remove(file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !gdown --id <File ID>\n","# # https://drive.google.com/drive/folders/14KcDLZPavwCDG9QIvuhcoM9mOE6QrHT9?usp=sharing\n","# # https://drive.google.com/file/d/1FuI9tD0WtnizMQVKiOdWrCHOO1TW8MKk/view?usp=sharing\n","# # https://drive.google.com/file/d/1ZYEczEoCGDhgZrxOOTUhYkDvnxTMNnuq/view?usp=sharing\n","# https://drive.google.com/file/d/1MY8jlBZymLCa6IfDYQxS57d6-umdowwd/view?usp=drive_link\n","# !gdown --id 1MY8jlBZymLCa6IfDYQxS57d6-umdowwd"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# https://drive.google.com/file/d/1MY8jlBZymLCa6IfDYQxS57d6-umdowwd/view?usp=drive_link\n","!gdown --id 1ZYEczEoCGDhgZrxOOTUhYkDvnxTMNnuq"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import zipfile\n","\n","with zipfile.ZipFile('/kaggle/working/my_folder.zip', 'r') as zip_ref:\n","    zip_ref.extractall('Train/')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T18:29:09.571777Z","iopub.status.busy":"2024-04-27T18:29:09.571335Z","iopub.status.idle":"2024-04-27T18:29:09.586669Z","shell.execute_reply":"2024-04-27T18:29:09.585717Z","shell.execute_reply.started":"2024-04-27T18:29:09.571729Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of files in the directory: 4920\n","Number of files in the directory_norm: 6225\n"]}],"source":["import os\n","\n","# Directory path\n","directory = '/kaggle/working/Train/content/drive/MyDrive/augmented_image-10-march/glaucoma'\n","directory_normal = '/kaggle/working/Train/content/drive/MyDrive/augmented_image-10-march/normal'\n","\n","# Get list of files in the directory\n","files = os.listdir(directory)\n","\n","# Count the number of files\n","num_files = len(files)\n","# Get list of files in the directory\n","files_norm = os.listdir(directory_normal)\n","\n","# Count the number of files\n","num_files_norm = len(files_norm)\n","print(\"Number of files in the directory:\", num_files)\n","print(\"Number of files in the directory_norm:\", num_files_norm)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import random\n","from shutil import copyfile\n","from sklearn.model_selection import train_test_split\n","\n","def split_and_save_dataset(input_folder, output_folder, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2):\n","    # Create output folders for each class\n","    train_folder = os.path.join(output_folder, 'train')\n","    val_folder = os.path.join(output_folder, 'val')\n","    test_folder = os.path.join(output_folder, 'test')\n","\n","    for folder in [train_folder, val_folder, test_folder]:\n","        os.makedirs(os.path.join(folder, 'normal'), exist_ok=True)\n","        os.makedirs(os.path.join(folder, 'glaucoma'), exist_ok=True)\n","\n","    # Get a list of all image file paths in the input folder for each class\n","    normal_paths = [os.path.join(input_folder, 'normal', filename) for filename in os.listdir(os.path.join(input_folder, 'normal')) if filename.endswith(('.jpg', '.jpeg', '.png'))]\n","    glaucoma_paths = [os.path.join(input_folder, 'glaucoma', filename) for filename in os.listdir(os.path.join(input_folder, 'glaucoma')) if filename.endswith(('.jpg', '.jpeg', '.png'))]\n","\n","    # Shuffle the lists to randomize the order\n","    random.shuffle(normal_paths)\n","    random.shuffle(glaucoma_paths)\n","\n","    # Split the dataset for each class\n","    normal_train, normal_test = train_test_split(normal_paths, test_size=test_ratio, random_state=42)\n","    normal_train, normal_val = train_test_split(normal_train, test_size=val_ratio / (train_ratio + val_ratio), random_state=42)\n","\n","    glaucoma_train, glaucoma_test = train_test_split(glaucoma_paths, test_size=test_ratio, random_state=42)\n","    glaucoma_train, glaucoma_val = train_test_split(glaucoma_train, test_size=val_ratio / (train_ratio + val_ratio), random_state=42)\n","\n","    # Copy images to respective folders\n","    for path in normal_train:\n","        copyfile(path, os.path.join(train_folder, 'normal', os.path.basename(path)))\n","\n","    for path in normal_val:\n","        copyfile(path, os.path.join(val_folder, 'normal', os.path.basename(path)))\n","\n","    for path in normal_test:\n","        copyfile(path, os.path.join(test_folder, 'normal', os.path.basename(path)))\n","\n","    for path in glaucoma_train:\n","        copyfile(path, os.path.join(train_folder, 'glaucoma', os.path.basename(path)))\n","\n","    for path in glaucoma_val:\n","        copyfile(path, os.path.join(val_folder, 'glaucoma', os.path.basename(path)))\n","\n","    for path in glaucoma_test:\n","        copyfile(path, os.path.join(test_folder, 'glaucoma', os.path.basename(path)))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_folder = '/kaggle/working/Train/content/drive/MyDrive/augmented_image-10-march'\n","output_folder = '/kaggle/working/Train_split'\n","# train_ratio = 0.7\n","# val_ratio = 0.2\n","# test_ratio = 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["split_and_save_dataset(input_folder, output_folder, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-04-27T16:32:10.724226Z","iopub.status.busy":"2024-04-27T16:32:10.723526Z","iopub.status.idle":"2024-04-27T17:30:26.381501Z","shell.execute_reply":"2024-04-27T17:30:26.380310Z","shell.execute_reply.started":"2024-04-27T16:32:10.724192Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["YOLOv8x-cls summary: 183 layers, 57422840 parameters, 57422840 gradients, 155.3 GFLOPs\n","YOLOv8x-cls summary: 183 layers, 57422840 parameters, 57422840 gradients, 155.3 GFLOPs\n","Transferred 302/302 items from pretrained weights\n","Ultralytics YOLOv8.2.3 ğŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8x-cls.yaml, data=/kaggle/working/Train_split, epochs=20, time=None, patience=5, batch=32, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.5, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train2\n","\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/Train_split/train... found 7800 images in 2 classes âœ… \n","\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/Train_split/val... found 1116 images in 2 classes âœ… \n","\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/Train_split/test... found 2229 images in 2 classes âœ… \n"]},{"name":"stderr","output_type":"stream","text":["2024-04-27 16:32:16,869\tINFO util.py:124 -- Outdated packages:\n","  ipywidgets==7.7.1 found, needs ipywidgets>=8\n","Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","2024-04-27 16:32:17,667\tINFO util.py:124 -- Outdated packages:\n","  ipywidgets==7.7.1 found, needs ipywidgets>=8\n","Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","2024-04-27 16:32:18.351544: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-27 16:32:18.351604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-27 16:32:18.353100: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["Overriding model.yaml nc=1000 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n","  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n","  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n","  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n","  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n","  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n","  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n","  7                  -1  1   7375360  ultralytics.nn.modules.conv.Conv             [640, 1280, 3, 2]             \n","  8                  -1  3  27865600  ultralytics.nn.modules.block.C2f             [1280, 1280, 3, True]         \n","  9                  -1  1   1643522  ultralytics.nn.modules.head.Classify         [1280, 2]                     \n","YOLOv8x-cls summary: 183 layers, 56144402 parameters, 56144402 gradients, 154.3 GFLOPs\n","Transferred 300/302 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train2', view at http://localhost:6006/\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshje494\u001b[0m (\u001b[33mhttps-wandb-ai-background-curves-svg-2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.16.6 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240427_163223-gbrwfsit</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/https-wandb-ai-background-curves-svg-2/YOLOv8/runs/gbrwfsit' target=\"_blank\">train2</a></strong> to <a href='https://wandb.ai/https-wandb-ai-background-curves-svg-2/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/https-wandb-ai-background-curves-svg-2/YOLOv8' target=\"_blank\">https://wandb.ai/https-wandb-ai-background-curves-svg-2/YOLOv8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/https-wandb-ai-background-curves-svg-2/YOLOv8/runs/gbrwfsit' target=\"_blank\">https://wandb.ai/https-wandb-ai-background-curves-svg-2/YOLOv8/runs/gbrwfsit</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Train_split/train... 7800 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7800/7800 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Train_split/val... 1116 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1116/1116 [00:00<?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 320 train, 320 val\n","Using 4 dataloader workers\n","Logging results to \u001b[1mruns/classify/train2\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:13<00:00,  1.34it/s],  1.98it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.641          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/20       5.7G     0.6437         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:30<00:00,  1.62it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:14<00:00,  1.21it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.692          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       3/20      5.72G     0.6027         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:32<00:00,  1.60it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:14<00:00,  1.23it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.728          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       4/20      5.71G      0.559         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:33<00:00,  1.59it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.20it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.808          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       5/20      5.72G     0.5128         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:37<00:00,  1.55it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.837          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       6/20      5.71G     0.4866         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:31<00:00,  1.61it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.14it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.855          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       7/20      5.72G     0.4543         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:29<00:00,  1.64it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.861          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       8/20      5.71G     0.4271         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:32<00:00,  1.59it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.888          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       9/20      5.72G     0.4054         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:32<00:00,  1.60it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:14<00:00,  1.26it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.908          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      10/20      5.71G     0.3792         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:35<00:00,  1.57it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.913          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      11/20      5.72G     0.3586         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:35<00:00,  1.57it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.918          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      12/20      5.71G     0.3314         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:25<00:00,  1.68it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.932          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      13/20      5.72G     0.3252         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:27<00:00,  1.65it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.932          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      14/20      5.71G     0.3106         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:30<00:00,  1.62it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.14it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all       0.94          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      15/20      5.72G     0.2926         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:30<00:00,  1.62it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.13it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.943          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      16/20      5.71G     0.2791         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:25<00:00,  1.68it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.949          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      17/20      5.72G     0.2847         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:29<00:00,  1.63it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.952          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      18/20      5.71G     0.2724         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:32<00:00,  1.60it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.952          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      19/20      5.72G     0.2731         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:28<00:00,  1.64it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:14<00:00,  1.23it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.953          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      20/20      5.71G     0.2633         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244/244 [02:28<00:00,  1.65it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:14<00:00,  1.28it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all      0.953          1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","20 epochs completed in 0.949 hours.\n","Optimizer stripped from runs/classify/train2/weights/last.pt, 112.5MB\n","Optimizer stripped from runs/classify/train2/weights/best.pt, 112.5MB\n","\n","Validating runs/classify/train2/weights/best.pt...\n","Ultralytics YOLOv8.2.3 ğŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n","YOLOv8x-cls summary (fused): 133 layers, 56125762 parameters, 0 gradients, 153.8 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/Train_split/train... found 7800 images in 2 classes âœ… \n","\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/Train_split/val... found 1116 images in 2 classes âœ… \n","\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/Train_split/test... found 2229 images in 2 classes âœ… \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:12<00:00,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.953          1\n","Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/train2\u001b[0m\n","Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='2.240 MB of 109.514 MB uploaded\\r'), FloatProgress(value=0.02044963005603131, max=â€¦"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–ˆâ–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>lr/pg1</td><td>â–ƒâ–†â–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–</td></tr><tr><td>lr/pg2</td><td>â–ƒâ–†â–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–</td></tr><tr><td>metrics/accuracy_top1</td><td>â–â–‚â–ƒâ–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/accuracy_top5</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‡â–‡â–†â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>val/loss</td><td>â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>6e-05</td></tr><tr><td>lr/pg1</td><td>6e-05</td></tr><tr><td>lr/pg2</td><td>6e-05</td></tr><tr><td>metrics/accuracy_top1</td><td>0.95251</td></tr><tr><td>metrics/accuracy_top5</td><td>1.0</td></tr><tr><td>model/GFLOPs</td><td>154.313</td></tr><tr><td>model/parameters</td><td>56144402</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>4.038</td></tr><tr><td>train/loss</td><td>0.26332</td></tr><tr><td>val/loss</td><td>0.38326</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">train2</strong> at: <a href='https://wandb.ai/https-wandb-ai-background-curves-svg-2/YOLOv8/runs/gbrwfsit' target=\"_blank\">https://wandb.ai/https-wandb-ai-background-curves-svg-2/YOLOv8/runs/gbrwfsit</a><br/>Synced 6 W&B file(s), 15 media file(s), 1 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240427_163223-gbrwfsit/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO('yolov8x-cls.yaml')  # build a new model from YAML\n","model = YOLO('yolov8x-cls.pt')  # load a pretrained model (recommended for training)\n","model = YOLO('yolov8x-cls.yaml').load('yolov8x-cls.pt')  # build from YAML and transfer weights\n","\n","# Train the model\n","results = model.train(data='/kaggle/working/Train_split', epochs=20, imgsz=320,batch=32,patience=5, optimizer='SGD',dropout=0.5,device=0,lr0=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
